2018/01/01 архив
2018/01/02 жесткие ссылки с пред. и вперёд
Настройка: год заново или с предыдущего, месяц заново (с начала года) или с предыдущего

compact - удалять 104, 0, прилеплять маленькие

как узнавать об аварийном завершении — в команде проверки

тестировать через сравнение tar-архивов, проверить запаковку/распаковку VZ-контейнера и корня системы

а точно ли пропускаем уже добавленные файлы, не читая? сравнивая по дате.

каждый файл в каталоге в отдельный архив (для mysql)

После сохранения ставим флаг завершённости создания архива (статус, дата - timestamp), чтобы знать, когда
архив сделан.

info command

не удалять битые ссылки? Отдельной команой удаять всё битое

genbackupdata

Простота обращения к архивным данным: представление в виде слепком на разные даты (как выводить список дат?) — fuse?

Концепция по архивированию и восстановлению

password - в тесты

Встроенный nice (паузы между вызовами zpaq)

Поддержка снимков LVM

Проверить с новым metastore

To mark a file as deleted from a zpaq archive: zpaq add archive.zpaq nul: -to file_to_delete

Wait for
zpaq x archive -repack new_archive.zpaq

http://wertarbyte.de/tartarus.shtml

http://burp.grke.org/index.html
http://www.kudos.be/Articles/Migrating_from_Bacula_to_Burp.html

проверить на dash (и сделать замену realpath)

подбирать короткие пустые файлы (как-то их надо уметь откатывать), пока не закончатся.

pax: слишком длинные имена??

Дописать тест на удаление файлов внутри (и каталогов) и в основном архиве
Удалять просто сравнением списков каталогов? (Каталоги удаляет сам, а вот файлы в основном архиве...)

Check https://github.com/bup/bup
https://wiki.thingsandstuff.org/Backup


Блокировку архива в eterbackup во время работы

Видимо, нужно делать ещё exclude-files, который будет передаваться в программу

Нужно проверить тест: Не распаковывает архивы, в которых только пустые каталоги
Написать автору zpaq с примером (написал)

metastore округляет время до целых секунд! (ждём новой версии)

Одно дело backup, другое — архив для длительного хранения. Ему нужен контроль.
zpaq плохо подвержен тестированию (нельзя ли просто проверять целостность блоков, без распаковки файлов?)

Для больших архивов из мелких данных можно было бы запускать сжатие несколько раз в один архив. Этакая эмуляция разбития по размеру.

Вопросы:
1. Сжатие на ходу (stdin) - очень интересно
2. Ограничение размера тома архива - для виртуалок
3. Права - могут и подождать теперь (обещает сделать в новой версии)
4. Игнорирование подкаталогов (только файлы) - подождёт (или можно сделать своими силами?)

Виртуалку замораживать на время архивирования

Важный вопрос: как замораживать данные на время бэкапа?

Неактуально:
Сделать сборку одного файла и её использовать?

Запись версии, с которой сделан архив, чтобы сверять при восстановлении и изменении совместимости

Сделать ротацию день - неделя - месяц - год

Локальное хранение вести отдельно.

Типы данных: БД (тут может быть удобна ротация), файлы, seafile, образы виртуалок.

Сделать поддержку удалённого бэкапа (когда локально только индексы)
типа remote — при необходимости скачивает индексы. По идее не должен делать на сервере ничего удалять?
Это нужно делать через промежуточный сервер.
Место архивирование <-> сервер архивирования -> хранилище архивирования
После создания архива отправляем его на сервер через вызов внешней указанной команды/конфига?

Нужно идти в сторону «статической» линковки библиотек для shell. Это типа npm для shell,
чтобы можно было везде использовать библиотеку без зависимости на неё в отдельном пакете.

Предел размера файла архива. Также начинать вести новый, если много инкрементов.
Хранить на gluster в garbage. Файлы брать с nun (там и проводить операции).
Шифровать с помощью encfs.

Ротация zpaq: удалять большой, склеивать маленькие и работать над ними?
Возможно, можно просто удалять ненужные? Проверить, как работает удаление файлов
при добавлении архив.

Сохранять контрольные суммы по архивам, проверять целостность: это можно делать, но отдельным средством, просто на уровне файлов. Рекурсивный md5sum такой. Наверняка есть готовый.

Для режима, когда локально архив не сохраняется
zpaq: If the index is present but part 1 is not, then it is assumed that all of the parts have been moved. The number of versions in the index is counted and a new part is created using the next available version number, and the index is updated.

rsnapshot - можно ли приспособить для локальных копий?

Должен быть только read-only доступ с места бэкапа.

Понятие виртуального архива: когда в реальности файлы не находятся внутри архива. Но у него имеется контрольная сумма.
